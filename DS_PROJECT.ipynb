{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_PROJECT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gW4Z8i16_RI4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collabrative filtering using deep neural networks\n",
        "\n",
        "Reference :- [Neural Collaborative Filtering](https://arxiv.org/abs/1708.05031)"
      ],
      "metadata": {
        "id": "e1Z1Y-fi6og6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjlzqZjIm119",
        "outputId": "16079d49-4031-4d98-9be6-cafa98915707"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULauuEp7j9JL",
        "outputId": "1b5d3056-8cf6-4dc2-8059-f99c5808d810"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf '/content/movie_lens/ml-100k'"
      ],
      "metadata": {
        "id": "nmX6ECWXXz63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/movie_lens/\"\n",
        "ckpt_dir = './drive/MyDrive/Extra/DS/ckpt/'\n",
        "tensorboard_dir = './drive/MyDrive/Extra/DS/training/'\n",
        "if not os.path.isdir(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "if not os.path.isdir(ckpt_dir):\n",
        "    os.makedirs(ckpt_dir)\n",
        "if not os.path.isdir(tensorboard_dir):\n",
        "    os.makedirs(tensorboard_dir)"
      ],
      "metadata": {
        "id": "ItQFIsnMADY_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter(tensorboard_dir)\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "Q-hyJ3lCpIsm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip \"/content/ml-100k.zip\" -d \"/content/movie_lens/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32p6PwTU_vef",
        "outputId": "3109cdcd-8f6d-448d-e487-dbb930d8ecde"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-17 13:53:31--  https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  30.9MB/s    in 0.2s    \n",
            "\n",
            "2022-04-17 13:53:31 (30.9 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  /content/ml-100k.zip\n",
            "   creating: /content/movie_lens/ml-100k/\n",
            "  inflating: /content/movie_lens/ml-100k/allbut.pl  \n",
            "  inflating: /content/movie_lens/ml-100k/mku.sh  \n",
            "  inflating: /content/movie_lens/ml-100k/README  \n",
            "  inflating: /content/movie_lens/ml-100k/u.data  \n",
            "  inflating: /content/movie_lens/ml-100k/u.genre  \n",
            "  inflating: /content/movie_lens/ml-100k/u.info  \n",
            "  inflating: /content/movie_lens/ml-100k/u.item  \n",
            "  inflating: /content/movie_lens/ml-100k/u.occupation  \n",
            "  inflating: /content/movie_lens/ml-100k/u.user  \n",
            "  inflating: /content/movie_lens/ml-100k/u1.base  \n",
            "  inflating: /content/movie_lens/ml-100k/u1.test  \n",
            "  inflating: /content/movie_lens/ml-100k/u2.base  \n",
            "  inflating: /content/movie_lens/ml-100k/u2.test  \n",
            "  inflating: /content/movie_lens/ml-100k/u3.base  \n",
            "  inflating: /content/movie_lens/ml-100k/u3.test  \n",
            "  inflating: /content/movie_lens/ml-100k/u4.base  \n",
            "  inflating: /content/movie_lens/ml-100k/u4.test  \n",
            "  inflating: /content/movie_lens/ml-100k/u5.base  \n",
            "  inflating: /content/movie_lens/ml-100k/u5.test  \n",
            "  inflating: /content/movie_lens/ml-100k/ua.base  \n",
            "  inflating: /content/movie_lens/ml-100k/ua.test  \n",
            "  inflating: /content/movie_lens/ml-100k/ub.base  \n",
            "  inflating: /content/movie_lens/ml-100k/ub.test  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "\n",
        "df = pd.read_csv('/content/movie_lens/ml-100k/u.data','\\t',names = names)\n",
        "# df.rename(columns = {'user_id':'userId', 'item_id':'movieId'}, inplace = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8sf9tAmZgfN",
        "outputId": "c9dbde73-24c5-4835-e03c-e2abf1c4a2c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HT70yfAwZjBG",
        "outputId": "f929cd2f-c8ca-4ea7-a961-556a56bde6bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       user_id  item_id  rating  timestamp\n",
              "0          196      242       3  881250949\n",
              "1          186      302       3  891717742\n",
              "2           22      377       1  878887116\n",
              "3          244       51       2  880606923\n",
              "4          166      346       1  886397596\n",
              "...        ...      ...     ...        ...\n",
              "99995      880      476       3  880175444\n",
              "99996      716      204       5  879795543\n",
              "99997      276     1090       1  874795795\n",
              "99998       13      225       2  882399156\n",
              "99999       12      203       3  879959583\n",
              "\n",
              "[100000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f2885f1-0236-47f7-8287-883f46086799\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>880</td>\n",
              "      <td>476</td>\n",
              "      <td>3</td>\n",
              "      <td>880175444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>716</td>\n",
              "      <td>204</td>\n",
              "      <td>5</td>\n",
              "      <td>879795543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>276</td>\n",
              "      <td>1090</td>\n",
              "      <td>1</td>\n",
              "      <td>874795795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>13</td>\n",
              "      <td>225</td>\n",
              "      <td>2</td>\n",
              "      <td>882399156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>12</td>\n",
              "      <td>203</td>\n",
              "      <td>3</td>\n",
              "      <td>879959583</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f2885f1-0236-47f7-8287-883f46086799')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f2885f1-0236-47f7-8287-883f46086799 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f2885f1-0236-47f7-8287-883f46086799');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.user_id.unique()), len(df.item_id.unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbHIfIYBdYI7",
        "outputId": "dfd8a2f5-0911-4ef2-c3e7-4c41c556048b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 1682)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.user_id = df.user_id.astype('category').cat.codes.values\n",
        "df.item_id = df.item_id.astype('category').cat.codes.values"
      ],
      "metadata": {
        "id": "528fmeYhdYKj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp, test= train_test_split(df,test_size=0.1)\n",
        "train, val = train_test_split(temp, test_size=0.23) # 0.23 x 0.9 = 0.2"
      ],
      "metadata": {
        "id": "1XI4YiMGdYMX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpNAYAgwdYN5",
        "outputId": "0d31074c-3b5c-4e65-bceb-72ebe5f4ff19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69300"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train.user_id.unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mEdPH8mm29A",
        "outputId": "7fb9d407-5ef6-4931-887c-0c7f0544b3d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "943"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NCF(nn.Module):\n",
        "  def __init__(self,args):\n",
        "    super(NCF,self).__init__()\n",
        "    self.no_users = args['n_users']\n",
        "    self.no_movies = args['n_movies']\n",
        "    self.no_latent_users = args['n_latent_variables_u']\n",
        "    self.no_latent_movie = args['n_latent_variables_m']\n",
        "    self.no_latent_mf = args['n_latent_variables_mf']\n",
        "\n",
        "    self.movie_embedding = nn.Embedding(self.no_movies+1, self.no_latent_movie)\n",
        "    self.movie_embedding_mf = nn.Embedding(self.no_movies+1, self.no_latent_mf)\n",
        "    self.user_embedding = nn.Embedding(self.no_users+1, self.no_latent_users)\n",
        "    self.user_embedding_mf = nn.Embedding(self.no_users+1, self.no_latent_mf)\n",
        "\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.bn1 = nn.BatchNorm1d(200)\n",
        "    self.bn2 = nn.BatchNorm1d(100)\n",
        "    \n",
        "\n",
        "    self.fc1 = nn.Linear(self.no_latent_movie+self.no_latent_users,200)\n",
        "    self.fc2 = nn.Linear(200,100)\n",
        "    self.fc3 = nn.Linear(100,50)\n",
        "    self.fc4 = nn.Linear(50,20)\n",
        "    self.fc5 = nn.Linear(20,1)\n",
        "    self.fc6 = nn.Linear(2,100)\n",
        "    self.fc7 = nn.Linear(100,100)\n",
        "    self.fc8 = nn.Linear(100,1)\n",
        "\n",
        "\n",
        "  def forward(self,u,m):\n",
        "    mx= self.movie_embedding(m)\n",
        "    mx = self.flatten(mx)\n",
        "    mx = self.dropout(mx)\n",
        "\n",
        "    mxf= self.movie_embedding_mf(m)\n",
        "    mxf = self.flatten(mxf)\n",
        "    mxf = self.dropout(mxf)\n",
        "\n",
        "    ux= self.user_embedding(u)\n",
        "    ux = self.flatten(ux)\n",
        "    ux = self.dropout(ux)\n",
        "\n",
        "    uxf= self.user_embedding_mf(u)\n",
        "    uxf = self.flatten(uxf)\n",
        "    uxf = self.dropout(uxf)\n",
        "\n",
        "    out = torch.cat([mx, ux], dim=1)\n",
        "    out = self.dropout(out)\n",
        "    out = self.fc1(out)\n",
        "    out = self.bn1(out)\n",
        "    out = self.dropout(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.bn2(out)\n",
        "    out = self.dropout(out)\n",
        "    out = self.fc3(out)\n",
        "    out = self.fc4(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc5(out)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    out1 = torch.sum(mxf* uxf,dim = 1)\n",
        "    out1 = torch.unsqueeze(out1,1)\n",
        "    out = torch.cat([out1, out], dim=1)\n",
        "    out = self.fc6(out)\n",
        "    out = self.fc7(out)\n",
        "    out = self.fc8(out)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "LSHJpKhEdYPq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Load_MVLENS(Dataset):\n",
        "\n",
        "  def __init__(self,df):\n",
        "    \n",
        "\n",
        "    x=np.array([np.array(df.user_id.values),np.array(df.item_id.values)])\n",
        "    x = x.T\n",
        "    y=np.array(df.rating.values)\n",
        "\n",
        "    self.x_train=torch.tensor(x,dtype=torch.int32)\n",
        "    self.y_train=torch.tensor(y,dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    return self.x_train[idx],self.y_train[idx]"
      ],
      "metadata": {
        "id": "R3skVZoVdYUD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_NCF(model,num_epochs,batch_size,lr,save_interval):\n",
        "  \n",
        "  print(\"Training\")\n",
        "  train_dataset = Load_MVLENS(train)\n",
        "  val_dataset = Load_MVLENS(val)\n",
        "  train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "  val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "  model.to(device)\n",
        "  model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "  # criterion = RMSELoss(reduction = 'sum')\n",
        "  criterion = nn.MSELoss(reduction = 'sum')\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    avg = []\n",
        "    for batch_idx,(data,target) in enumerate(train_loader):\n",
        "      U = data[:,0].to(device)\n",
        "      M = data[:,1].to(device)\n",
        "      U = torch.unsqueeze(U,1)\n",
        "      M = torch.unsqueeze(M,1)\n",
        "      target = target.float().view((len(target),1))\n",
        "      target = target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(U,M)\n",
        "      loss = criterion(output, target)\n",
        "      avg.append(loss.item())\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    epoch_loss = np.mean(avg)\n",
        "    \n",
        "    if(epoch % save_interval == 0):\n",
        "      state = {\n",
        "                  'epoch': epoch,\n",
        "                  'state_dict': model.module.state_dict(),\n",
        "                  'optimizer': optimizer.state_dict()\n",
        "                  # 'scheduler': scheduler.state_dict()\n",
        "                  }\n",
        "      torch.save(state, ckpt_dir +'epoch_'+str(epoch)+'_ckpt.t7')\n",
        "    \n",
        "    val_loss= val_NCF(model,val_loader)\n",
        "\n",
        "    writer.add_scalar('Train loss', epoch_loss, epoch)\n",
        "    writer.add_scalar('Val loss', val_loss, epoch)\n",
        "\n",
        "    print(\"Epoch {} Train loss: {},  Val loss: {}\".format(epoch,epoch_loss,val_loss))\n",
        "\n"
      ],
      "metadata": {
        "id": "gdpwxMgedYb1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_NCF(model,val_loader):\n",
        "  batch_size = 64\n",
        "  val_loss = 0.0\n",
        "  # criterion = RMSELoss(reduction='sum')\n",
        "  criterion = nn.MSELoss(reduction = 'sum')\n",
        "  model.eval()\n",
        "  avg = []\n",
        "  with torch.no_grad():\n",
        "    for batch_idx,(data,target) in enumerate(val_loader):\n",
        "        U = data[:,0].to(device)\n",
        "        M = data[:,1].to(device)\n",
        "        U = torch.unsqueeze(U,1)\n",
        "        M = torch.unsqueeze(M,1)\n",
        "        target = target.float().view((len(target),1))\n",
        "        target = target.to(device)\n",
        "        output = model(U,M)\n",
        "        loss = criterion(output, target)\n",
        "        avg.append(loss.item())\n",
        "        # val_loss+=loss.item()\n",
        "\n",
        "  val_loss = np.mean(avg)\n",
        "  return val_loss"
      ],
      "metadata": {
        "id": "MWXCahMSzoCo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {'n_users':len(df.user_id.unique()),'n_movies':len(df.item_id.unique()),'n_latent_variables_u':8,'n_latent_variables_m':10,'n_latent_variables_mf':3}\n",
        "NCF_model = NCF(args)\n",
        "train_NCF(NCF_model,num_epochs = 100,batch_size=64,lr = 1e-3,save_interval=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzCvpOTcdYdP",
        "outputId": "02f8f25b-5e02-44e3-f6bb-16f8f124bd40"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training\n",
            "Epoch 0 Train loss: 87.35583280878605,  Val loss: 80.13437345292833\n",
            "Epoch 1 Train loss: 80.1442201707722,  Val loss: 76.046039863869\n",
            "Epoch 2 Train loss: 77.39733747233974,  Val loss: 72.31630504278489\n",
            "Epoch 3 Train loss: 74.63820350203157,  Val loss: 73.0882174173991\n",
            "Epoch 4 Train loss: 72.25939038629787,  Val loss: 67.87162923224179\n",
            "Epoch 5 Train loss: 70.00347452700854,  Val loss: 66.64395809173584\n",
            "Epoch 6 Train loss: 68.45748622045403,  Val loss: 65.76105023607795\n",
            "Epoch 7 Train loss: 67.20206766665697,  Val loss: 63.62404838609107\n",
            "Epoch 8 Train loss: 66.10205698761804,  Val loss: 63.80223706327838\n",
            "Epoch 9 Train loss: 65.01309643689946,  Val loss: 61.9218182210569\n",
            "Epoch 10 Train loss: 64.25938850888916,  Val loss: 62.21819284815847\n",
            "Epoch 11 Train loss: 63.673668288127864,  Val loss: 60.163164815784974\n",
            "Epoch 12 Train loss: 62.82215253666167,  Val loss: 61.42904090881348\n",
            "Epoch 13 Train loss: 62.463872326598164,  Val loss: 59.823846605088974\n",
            "Epoch 14 Train loss: 62.32862337980684,  Val loss: 60.09374471358311\n",
            "Epoch 15 Train loss: 61.638955867411575,  Val loss: 59.01661610308989\n",
            "Epoch 16 Train loss: 61.26934824667919,  Val loss: 58.22167018607811\n",
            "Epoch 17 Train loss: 60.74553452348225,  Val loss: 58.86877733984111\n",
            "Epoch 18 Train loss: 60.65461272347997,  Val loss: 58.910371444843435\n",
            "Epoch 19 Train loss: 60.279240887361,  Val loss: 57.679707497726255\n",
            "Epoch 20 Train loss: 60.05867139300261,  Val loss: 58.41597789010884\n",
            "Epoch 21 Train loss: 59.937007090391546,  Val loss: 57.80875756416792\n",
            "Epoch 22 Train loss: 59.665957037872005,  Val loss: 59.167659082530456\n",
            "Epoch 23 Train loss: 59.24149788867954,  Val loss: 58.067164839049916\n",
            "Epoch 24 Train loss: 59.16511101691897,  Val loss: 58.16917274616383\n",
            "Epoch 25 Train loss: 58.790760978987564,  Val loss: 57.660221976998415\n",
            "Epoch 26 Train loss: 58.80730904942845,  Val loss: 57.57933166880667\n",
            "Epoch 27 Train loss: 58.59638718863053,  Val loss: 57.218889036296325\n",
            "Epoch 28 Train loss: 58.50883798431932,  Val loss: 59.70046588520945\n",
            "Epoch 29 Train loss: 57.965952724411,  Val loss: 57.22247739485753\n",
            "Epoch 30 Train loss: 57.87065047372411,  Val loss: 60.120493847646834\n",
            "Epoch 31 Train loss: 57.629668027079994,  Val loss: 57.93271858309522\n",
            "Epoch 32 Train loss: 57.391642458661224,  Val loss: 57.34378001130658\n",
            "Epoch 33 Train loss: 57.30047928131188,  Val loss: 57.70601246092055\n",
            "Epoch 34 Train loss: 57.10201756379611,  Val loss: 57.40829924595209\n",
            "Epoch 35 Train loss: 56.883580066050406,  Val loss: 57.60807220435437\n",
            "Epoch 36 Train loss: 56.61783921443414,  Val loss: 57.36717401904824\n",
            "Epoch 37 Train loss: 56.52781114904064,  Val loss: 57.15158420727577\n",
            "Epoch 38 Train loss: 56.22920187952776,  Val loss: 57.57470898569366\n",
            "Epoch 39 Train loss: 56.07458976717427,  Val loss: 57.63560647140314\n",
            "Epoch 40 Train loss: 55.904649718646525,  Val loss: 57.97537658832692\n",
            "Epoch 41 Train loss: 55.67223654383327,  Val loss: 57.8969412556401\n",
            "Epoch 42 Train loss: 55.52023085244585,  Val loss: 57.631548375259214\n",
            "Epoch 43 Train loss: 55.10923958529175,  Val loss: 57.21753465393443\n",
            "Epoch 44 Train loss: 55.29994354529834,  Val loss: 57.680533562177494\n",
            "Epoch 45 Train loss: 55.046859424200086,  Val loss: 57.476224375359806\n",
            "Epoch 46 Train loss: 55.03370789433671,  Val loss: 57.49138085047404\n",
            "Epoch 47 Train loss: 54.708032114904235,  Val loss: 58.94729616023876\n",
            "Epoch 48 Train loss: 54.38596849626451,  Val loss: 58.04663405006315\n",
            "Epoch 49 Train loss: 54.22554742420369,  Val loss: 58.022114553569274\n",
            "Epoch 50 Train loss: 54.110590979663286,  Val loss: 58.19867794013318\n",
            "Epoch 51 Train loss: 54.08204059301431,  Val loss: 57.819428449795566\n",
            "Epoch 52 Train loss: 54.09229054367333,  Val loss: 57.5360369152493\n",
            "Epoch 53 Train loss: 54.00032573393507,  Val loss: 57.300964178862394\n",
            "Epoch 54 Train loss: 53.58539058583155,  Val loss: 57.685946317366614\n",
            "Epoch 55 Train loss: 53.342129970631554,  Val loss: 57.60029272385585\n",
            "Epoch 56 Train loss: 53.131292052546364,  Val loss: 58.19742163905391\n",
            "Epoch 57 Train loss: 53.110617154192724,  Val loss: 57.75658031746193\n",
            "Epoch 58 Train loss: 53.03620570386216,  Val loss: 58.156368055461364\n",
            "Epoch 59 Train loss: 52.71783473683196,  Val loss: 57.76185533735487\n",
            "Epoch 60 Train loss: 52.75298331516932,  Val loss: 58.02122092541353\n",
            "Epoch 61 Train loss: 52.463970326981055,  Val loss: 57.37078766175258\n",
            "Epoch 62 Train loss: 52.44232071007388,  Val loss: 58.17822604709201\n",
            "Epoch 63 Train loss: 52.31888828999668,  Val loss: 57.60417096408797\n",
            "Epoch 64 Train loss: 52.24996858070212,  Val loss: 57.899051036363765\n",
            "Epoch 65 Train loss: 52.10434356224504,  Val loss: 57.29145735870173\n",
            "Epoch 66 Train loss: 52.00321230619788,  Val loss: 56.99801154784215\n",
            "Epoch 67 Train loss: 51.913987452964044,  Val loss: 57.445243747146044\n",
            "Epoch 68 Train loss: 51.71774351343664,  Val loss: 58.56090570379187\n",
            "Epoch 69 Train loss: 51.86600909492866,  Val loss: 57.546839902430406\n",
            "Epoch 70 Train loss: 51.82637502964404,  Val loss: 57.88069877506774\n",
            "Epoch 71 Train loss: 51.48080815238636,  Val loss: 57.681588796921716\n",
            "Epoch 72 Train loss: 51.65864046788942,  Val loss: 58.159784670229314\n",
            "Epoch 73 Train loss: 51.31102785443335,  Val loss: 58.218656354480316\n",
            "Epoch 74 Train loss: 51.44638520308589,  Val loss: 57.568641874525284\n",
            "Epoch 75 Train loss: 50.93691333795408,  Val loss: 57.78420030923537\n",
            "Epoch 76 Train loss: 51.11827787115743,  Val loss: 57.09210072034671\n",
            "Epoch 77 Train loss: 51.0889558624803,  Val loss: 58.16269271756396\n",
            "Epoch 78 Train loss: 50.7469861214621,  Val loss: 56.85477852527006\n",
            "Epoch 79 Train loss: 51.05275636498617,  Val loss: 57.278547451819904\n",
            "Epoch 80 Train loss: 50.81504552318118,  Val loss: 56.9094051313989\n",
            "Epoch 81 Train loss: 50.59552762250821,  Val loss: 57.66641753985558\n",
            "Epoch 82 Train loss: 50.52221274970311,  Val loss: 58.145626468422975\n",
            "Epoch 83 Train loss: 50.406127609154304,  Val loss: 57.122396757573256\n",
            "Epoch 84 Train loss: 50.21511334131299,  Val loss: 57.864842226475844\n",
            "Epoch 85 Train loss: 50.42063253584111,  Val loss: 56.70256392161051\n",
            "Epoch 86 Train loss: 50.21073568208506,  Val loss: 56.89189143828404\n",
            "Epoch 87 Train loss: 50.12544557108223,  Val loss: 58.21044261367233\n",
            "Epoch 88 Train loss: 50.296091461005524,  Val loss: 56.3052150114083\n",
            "Epoch 89 Train loss: 49.93891877326719,  Val loss: 56.683687157101105\n",
            "Epoch 90 Train loss: 50.13214169270664,  Val loss: 57.0300673496576\n",
            "Epoch 91 Train loss: 49.73049772126963,  Val loss: 56.84561086584021\n",
            "Epoch 92 Train loss: 49.762769720230736,  Val loss: 56.72838352933342\n",
            "Epoch 93 Train loss: 49.600315988669216,  Val loss: 57.557427983225125\n",
            "Epoch 94 Train loss: 49.83002322400376,  Val loss: 57.183761770342606\n",
            "Epoch 95 Train loss: 49.67794480152077,  Val loss: 55.99492382708891\n",
            "Epoch 96 Train loss: 49.54359132056972,  Val loss: 57.33706927005156\n",
            "Epoch 97 Train loss: 49.39702849771177,  Val loss: 56.36372421405934\n",
            "Epoch 98 Train loss: 49.4254318106978,  Val loss: 57.159757319791815\n",
            "Epoch 99 Train loss: 49.57364270429532,  Val loss: 57.02758985684242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "x=np.array([np.array(test.user_id.values),np.array(test.item_id.values)])\n",
        "x = x.T\n",
        "x = torch.tensor(x,dtype=torch.int32)\n",
        "U = x[:,0].to(device)\n",
        "M = x[:,1].to(device)\n",
        "U = torch.unsqueeze(U,1)\n",
        "M = torch.unsqueeze(M,1)\n",
        "pred = NCF_model(U, M).detach().cpu()\n",
        "y_hat_2 = np.round(pred)\n",
        "y_true = test.rating\n",
        "print(np.sqrt(mean_absolute_error(y_true, y_hat_2)))\n",
        "print(np.sqrt(mean_absolute_error(y_true, pred)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJS7rm5l2tZH",
        "outputId": "5d10fc94-7079-4962-caee-8b5f33cc7592"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8471717653463199\n",
            "0.8681949942503375\n"
          ]
        }
      ]
    }
  ]
}